{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%configure -f\n",
        "{\n",
        "\"conf\": {\n",
        "     \"spark.dynamicAllocation.disableIfMinMaxNotSpecified.enabled\": true,\n",
        "   }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "# Placeholders for input parameters\n",
        "anomaly_found = False\n",
        "anomaly_time = ''\n",
        "anomaly_location = ''\n",
        "blob_account_name = ''\n",
        "azure_storage_domain = ''\n",
        "input_ais_csv_file = ''\n",
        "input_image = ''\n",
        "input_image_low_res = ''\n",
        "ship_bb_image_low_res = '' \n",
        "ship_bb_image_high_res = ''\n",
        "ais_image = ''\n",
        "anomaly_image = ''\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Initiate logging\n",
        "import logging\n",
        "from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
        "from opencensus.ext.azure.trace_exporter import AzureExporter\n",
        "from opencensus.trace import config_integration\n",
        "from opencensus.trace.samplers import AlwaysOnSampler\n",
        "from opencensus.trace.tracer import Tracer\n",
        "\n",
        "config_integration.trace_integrations(['logging'])\n",
        "\n",
        "instrumentation_connection_string = mssparkutils.credentials.getSecretWithLS(\"keyvault\", \"AppInsightsConnectionString\")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.addHandler(AzureLogHandler(connection_string=instrumentation_connection_string))\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "tracer = Tracer(\n",
        "    exporter=AzureExporter(\n",
        "        connection_string=instrumentation_connection_string\n",
        "    ),\n",
        "    sampler=AlwaysOnSampler()\n",
        ")\n",
        "\n",
        "# Spool parameters\n",
        "run_time_parameters = {'custom_dimensions': {\n",
        "    'anomaly_found': anomaly_found,\n",
        "    'anomaly_location': anomaly_location,\n",
        "    'anomaly_time': anomaly_time,\n",
        "    'blob_account_name': blob_account_name, \n",
        "    'notebook_name': mssparkutils.runtime.context['notebookname']\n",
        "} }\n",
        "  \n",
        "logger.info(f\"{mssparkutils.runtime.context['notebookname']}: INITIALISED\", extra=run_time_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import json\n",
        "from azure.identity import ClientSecretCredential\n",
        "from azure.eventgrid import EventGridPublisherClient, EventGridEvent\n",
        "from datetime import datetime\n",
        "from urllib.parse import quote \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Get config values \n",
        "sc = spark.sparkContext\n",
        "spark = SparkSession.builder.appName(f'Anomaly Eval {mssparkutils.runtime.context}').getOrCreate()\n",
        "config_path = f\"abfss://configuration@{blob_account_name}.dfs.{azure_storage_domain}/config.global.json\"\n",
        "config = json.loads(''.join(sc.textFile(config_path).collect()))\n",
        "teams_webhook_endpoint = config['rule_sets']['teams_webhook_uri']\n",
        "alert_email = config['rule_sets']['alert_email']\n",
        "web_app_uri = config['rule_sets']['webapp_uri']\n",
        "\n",
        "\n",
        "# Setup Event Grid client \n",
        "subscription_id = TokenLibrary.getSecretWithLS(\"keyvault\", 'SubscriptionId')\n",
        "resource_group_name = TokenLibrary.getSecretWithLS(\"keyvault\", 'ResourceGroupName')\n",
        "event_grid_topic_name = TokenLibrary.getSecretWithLS(\"keyvault\", 'EventGridTopicName')\n",
        "event_grid_topic_endpoint = TokenLibrary.getSecretWithLS(\"keyvault\", 'EventGridTopicEndpointUri')\n",
        "tenant_id = TokenLibrary.getSecretWithLS(\"keyvault\", 'TenantID')\n",
        "client_id = TokenLibrary.getSecretWithLS(\"keyvault\", 'ADAppRegClientId')\n",
        "client_secret = TokenLibrary.getSecretWithLS(\"keyvault\", 'ADAppRegClientSecret')\n",
        "event_grid_topic = f'/subscriptions/{subscription_id}/resourceGroups/{resource_group_name}/providers/Microsoft.EventGrid/topics/{event_grid_topic_name}'\n",
        "credential = ClientSecretCredential(tenant_id, client_id, client_secret)\n",
        "client = EventGridPublisherClient(event_grid_topic_endpoint, credential)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Send Event Grid Event \n",
        "def format_time(t): \n",
        "    if isinstance(t, str): \n",
        "        return t \n",
        "    if isinstance(t, (float,int)):\n",
        "        return datetime.fromtimestamp(int(t)).isoformat()\n",
        "\n",
        "    return t \n",
        "\n",
        "def now(): \n",
        "    return datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S%Z\")\n",
        "\n",
        "def build_details_url(web_app_uri, params): \n",
        "    url_params = '&'.join([f'{k}={v}' for k,v in params.items()])\n",
        "    return f'https://{web_app_uri}/anomaly?{url_params}'\n",
        "\n",
        "def format_location(location): \n",
        "    ul = ''\n",
        "    lr = ''\n",
        "    for corner in anomaly_location.split('\\n'): \n",
        "        if corner.startswith('Upper Left'): \n",
        "            ul = corner \n",
        "        if corner.startswith('Lower Right'): \n",
        "            lr = corner \n",
        "\n",
        "    upper_left = ul.split(')')[0].replace('(', '').replace('Upper Left', '').replace(' ', '')\n",
        "    lower_right = lr.split(')')[0].replace('(', '').replace('Lower Right', '').replace(' ', '')\n",
        "    return f'{upper_left} X {lower_right}'\n",
        "\n",
        "\n",
        "\n",
        "if anomaly_found: \n",
        "    with tracer.span('Send anomaly alert to event grid'):\n",
        "        location = format_location(anomaly_location)\n",
        "        params = {\n",
        "            'date': anomaly_time,\n",
        "            'location': location,\n",
        "            'source_image': input_image_low_res,\n",
        "            'source_image_high_res': input_image,\n",
        "            'ship_bb_image': ship_bb_image_high_res,\n",
        "            'ship_bb_image_high_res': ship_bb_image_high_res,\n",
        "            'ais_image': ais_image,\n",
        "            'anomaly_image': anomaly_image\n",
        "        }\n",
        "        details_url = build_details_url(web_app_uri, params)       \n",
        "        event_data = {\n",
        "            'eventDate': now(), \n",
        "            'eventMetrics':{\n",
        "                'ais_csv_file': input_ais_csv_file,\n",
        "                'input_image': input_image,\n",
        "                'anomaly_location': location,\n",
        "                'anomaly_time': format_time(anomaly_time),\n",
        "                'event_detail_uri': details_url\n",
        "            },\n",
        "            'teams_webhook_endpoint': teams_webhook_endpoint,\n",
        "            'alert_email': alert_email\n",
        "\n",
        "        }\n",
        "        event = EventGridEvent(data = event_data, subject=\"MINTED/AnomalyAlert\", event_type=\"MINTED.ruleTriggered\", data_version=\"1.0\", topic=event_grid_topic)\n",
        "        from pprint import pprint \n",
        "        pprint(event_data)\n",
        "        client.send(event)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
